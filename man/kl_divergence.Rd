% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/distances.R
\name{kl_divergence}
\alias{kl_divergence}
\title{KL Divergence Between Multivariate Normals}
\usage{
kl_divergence(mu1, Sigma1, mu2, Sigma2)
}
\arguments{
\item{mu1}{Mean vector of the first distribution}

\item{Sigma1}{Covariance matrix of the first distribution}

\item{mu2}{Mean vector of the second distribution}

\item{Sigma2}{Covariance matrix of the second distribution}
}
\value{
The KL divergence (non-negative scalar)
}
\description{
Computes the Kullback-Leibler divergence from distribution 1 to distribution 2.
Note: KL divergence is asymmetric (not a true distance metric).
}
\examples{
mu1 <- c(0, 0)
Sigma1 <- diag(2)
mu2 <- c(1, 1)
Sigma2 <- matrix(c(2, 0.5, 0.5, 1), 2, 2)
kl_divergence(mu1, Sigma1, mu2, Sigma2)

}
